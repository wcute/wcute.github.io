<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="爬虫 bs4参考链接：https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html  实例1：利用百度搜索接口，编写url采集器 import requests from bs4 import BeautifulSoup  headers={&amp;apos;User-Agent&amp;apos;: &amp;apos;Mozilla/5.0">
<meta property="og:type" content="website">
<meta property="og:title" content="Python3-学习（爬虫实例）">
<meta property="og:url" content="http://wcute.github.io/python/Python3-学习（爬虫实例）.html">
<meta property="og:site_name" content="Hexo Test">
<meta property="og:description" content="爬虫 bs4参考链接：https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html  实例1：利用百度搜索接口，编写url采集器 import requests from bs4 import BeautifulSoup  headers={&amp;apos;User-Agent&amp;apos;: &amp;apos;Mozilla/5.0">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-12-10T13:10:08.878Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python3-学习（爬虫实例）">
<meta name="twitter:description" content="爬虫 bs4参考链接：https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html  实例1：利用百度搜索接口，编写url采集器 import requests from bs4 import BeautifulSoup  headers={&amp;apos;User-Agent&amp;apos;: &amp;apos;Mozilla/5.0">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wcute.github.io/python/Python3-学习（爬虫实例）.html">





  <title>Python3-学习（爬虫实例） | Hexo Test</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo Test</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

	<h1 class="post-title" itemprop="name headline">Python3-学习（爬虫实例）</h1>



</header>

      
      
      
      <div class="post-body">
        
        
          <h5 id="爬虫"><a href="#爬虫" class="headerlink" title="爬虫"></a>爬虫</h5><ul>
<li><p>bs4参考链接：<a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html" target="_blank" rel="noopener">https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html</a></p>
</li>
<li><p>实例1：利用百度搜索接口，编写url采集器</p>
<pre><code>import requests
from bs4 import BeautifulSoup

headers={&apos;User-Agent&apos;: &apos;Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0&apos;}

for i in range(1,100,10):
    bd_search=&quot;https://www.baidu.com/s?wd=inurl:/dede/login.php?&amp;pn=%s&quot; %str(i)
    r=requests.get(bd_search,headers=headers)
    soup=BeautifulSoup(r.text,&quot;lxml&quot;)
    url_list=soup.select(&quot;.t &gt; a&quot;)    # 获得所有class为t的标签
    for url in url_list:
        real_url=url[&quot;href&quot;]
        r=requests.get(real_url)
        print (r.url)
</code></pre></li>
<li><p>实例2： 爬取文章标题</p>
<pre><code>import requests
import re

def get_article():
    for x in range(1,59):
        url=&quot;http://zone.secevery.com/sort_ytpe-new__day-0__is_recommend-0_page-&quot;
        url=url+str(x)
        resp=requests.get(url)
        result=re.findall(br&apos;&lt;a href=&quot;http://zone.secevery.com/article/\d+&quot;&gt;(.*?)&lt;/a&gt;&apos;,resp.content)
        for article in result:
            print (article.decode(&apos;utf-8&apos;))

if __name__==&apos;__main__&apos;:
    get_article()
</code></pre></li>
<li><p>实例3： 爬取文章标题并写入文件</p>
<pre><code>#-*-coding UTF_8 -*-
import requests
import re
from bs4 import BeautifulSoup

headers={
    &apos;Host&apos;: &quot;zone.secevery.com&quot;,
    &apos;User-Agent&apos;:&apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36&apos;,
    &apos;Referer&apos;:&apos;https://www.baidu.com&apos;
}

def get_total_pages():
    url=&apos;http://zone.secevery.com/&apos;
    response=requests.get(url=url,headers=headers)
    soup=BeautifulSoup(response.content,&apos;html.parser&apos;)

    a=soup.find_all(&apos;a&apos;,href=re.compile(&apos;is_recommend-0__page-&apos;))
    a=str(a[-1])
    total_pages=a.split(&apos;-&apos;)[-1].split(&apos;&quot;&apos;)[0]
    return  total_pages

def get_total_titles(pages):
    titles=[]
    total_pages=int(pages)
    for page in range(1,int(total_pages)):
        url=&apos;http://zone.secevery.com/sort_type-new__day-0__is_recommend-0__page-%d&apos;%page
        resp=requests.get(url=url,headers=headers)
        soup=BeautifulSoup(resp.content,&apos;html.parser&apos;)
        a = soup.find_all(&apos;a&apos;,href=re.compile(r&apos;com/article&apos;))
        for i in a:
            if i.string != &quot;查看全部&quot;:
                titles.append(i.string)
    return titles

def write_txt(titles):
    with open(&apos;title1.txt&apos;,&apos;w&apos;) as f:
        for title in titles:
            f.write(title+&apos;\n&apos;)

if __name__==&apos;__main__&apos;:
    print(&apos;-&apos;*60)
    print(&quot;程序启动中......&quot;)
    print(&apos;-&apos;*60)
    pages=get_total_pages()
    print(&quot;总页数为：%s&quot; % pages)
    print(&apos;-&apos;*60)
    print(&quot;正在获取数据，请稍后....&quot;)
    titles=get_total_titles(pages)
    print(&apos;文件正在写入,请稍后...&apos;)
    print(&apos;-&apos;*60)
    write_txt(titles)
    print(&quot;well done!&quot;)
</code></pre></li>
<li><p>实例4：爬取补天公益SRC链接</p>
<pre><code>import requests
from requests.packages import urllib3
from bs4 import BeautifulSoup
# 项目大厅链接
# https://butian.360.cn/Reward/plan

# 厂商提交漏洞的链接
# https://butian.360.cn/Loo/submit?cid=61101

headers={
    &quot;Host&quot;: &quot;butian.360.cn&quot;,
    &quot;User-Agent&quot;:&quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:62.0) Gecko/20100101 Firefox/62.0&quot;,
    &quot;Accept&quot;: &quot;application/json, text/javascript, */*; q=0.01&quot;,
    &quot;Accept-Language&quot;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;,
    &quot;Referer&quot;: &quot;https://butian.360.cn/Reward/plan&quot;,
    &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded; charset=UTF-8&quot;,
    &quot;X-Requested-With&quot;: &quot;XMLHttpRequest&quot;,
    &quot;Content-Length&quot;: &quot;14&quot;,
    &quot;Cookie&quot;: &quot;test_cookie_enable=null; __huid=108OHneOmn%2FGBQ%2BJukK2rK3j4HhKMHdLMfd%2BokoEYRQKE%3D; __guid=91251416.1657029331559520500.1512282503171.2822; __DC_gid=90162694.998847747.1523438745794.1537231453981.287; smidV2=201804121919226e10578a54cc4cce100543952a4e7b000018db7a8e1407320; Q=u%3D360H2620192781%26n%3D%26le%3D%26m%3DZGHlWGWOWGWOWGWOWGWOWGWOZwHm%26qid%3D2620192781%26im%3D1_t0105d6cf9b508f72c8%26src%3Dpcw_webscan%26t%3D1; T=s%3D8b8f0bc6b26203525eb9f114ee626b0e%26t%3D1536202563%26lm%3D%26lf%3D2%26sk%3Daa11fbae76d233eeabdcbbb8abdf885b%26mt%3D1536202563%26rc%3D%26v%3D2.0%26a%3D1; __gid=67796994.160790607.1526525535847.1528973038214.14; UM_distinctid=1636c03266b578-07963af4955a558-4c312a7a-144000-1636c03266c426; __DC_monitor_count=20; PHPSESSID=ingp9jlm0d9v5tosb2do8bs8u7; __q__=1537231281479; test_cookie_enable=null; __DC_sid=138613664.439132718304839230.1537229417384.1438; wzwsconfirm=732968041ce27324ddd8dcf54d958661; wzwstemplate=Mw==; wzwschallenge=-1; ccpassport=5a26b60aa93bd3303aea3061a756590d; wzwsvtime=1537230292&quot;,
}

data={
    &quot;s&quot;:&quot;1&quot;,
    &quot;p&quot;:&quot;1&quot;,
    &quot;token&quot;:&quot;&quot;,
    &quot;sort&quot;:&quot;1&quot;
}

urllib3.disable_warnings()    # 消除警告

#获取厂商总页数
def get_total_pages():
    url=&quot;https://butian.360.cn/Reward/pub&quot;
    resp=requests.post(url=url,headers=headers,data=data,verify=False)
    company_info=resp.json()
    total_pages=company_info[&apos;data&apos;][&apos;count&apos;]
    return total_pages

#获取厂商ID
def get_all_company_id(total_pages):
    company_id=[]
    for x in range(1,int(total_pages)+1):
        print (&quot;正在获取第%d页列表&quot; %x)
        data[&apos;p&apos;]=x
        url=&quot;https://butian.360.cn/Reward/pub&quot;
        resp=requests.post(url=url,headers=headers,data=data,verify=False)
        info=resp.json()
        company_info=info[&apos;data&apos;][&apos;list&apos;]
        for company in company_info:
            company_id.append(company[&apos;company_id&apos;])
    return company_id

# 获取厂商域名
def get_all_company_host(company_id):
    hosts=[]
    print (&quot;正在获取域名，请稍后&quot;)
    for x in company_id:
        url=&quot;https://butian.360.cn/Loo/submit?cid=%d&quot; % int(x)
        resp=requests.get(url=url,headers=headers,data=data,verify=False)
        soup=BeautifulSoup(resp.content,&quot;html.parser&quot;)
        inp=soup.find_all(&apos;input&apos;)
        print (inp[4][&apos;value&apos;])
        hosts.append(inp[4][&apos;value&apos;])
    return hosts

# 写入txt文件
def write(hosts):
    with open(&apos;butian_spider.text&apos;,&apos;w&apos;) as f:
        for url in hosts:
            f.write(url+&apos;\n&apos;)

if __name__==&quot;__main__&quot;:
    total_pages=get_total_pages()
    company_id=get_all_company_id(total_pages)
    hosts=get_all_company_host(company_id)
    print (&quot;正在写入文件&quot;)
    write(hosts)
    print (&quot;成功写入&quot;)
</code></pre></li>
</ul>

        
      </div>
      
      
      
    </div>
    
    
    
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">wcute</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">25</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-5"><a class="nav-link" href="#爬虫"><span class="nav-number">1.</span> <span class="nav-text">爬虫</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">wcute</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
